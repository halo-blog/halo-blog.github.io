<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python网络数据采集 | HALO</title><meta name="keywords" content="Python,爬虫"><meta name="author" content="HALO"><meta name="copyright" content="HALO"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Python网络数据采集笔记  网络数据采集的基本原理 对网络爬虫通常的想法：  通过网站域名获取 HTML 数据 根据目标信息解析数据 存储目标信息 如果有必要，移动到另一个网页重复这个过程  Python实现网络连接 使用python获取网页，代码实现 123from urllib.request import urlopenhtml &#x3D; urlopen(&quot;http:&#x2F;&#x2F;www.ba"><meta property="og:type" content="article"><meta property="og:title" content="Python网络数据采集"><meta property="og:url" content="http://halo123.top/2020/03/24/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/index.html"><meta property="og:site_name" content="HALO"><meta property="og:description" content="Python网络数据采集笔记  网络数据采集的基本原理 对网络爬虫通常的想法：  通过网站域名获取 HTML 数据 根据目标信息解析数据 存储目标信息 如果有必要，移动到另一个网页重复这个过程  Python实现网络连接 使用python获取网页，代码实现 123from urllib.request import urlopenhtml &#x3D; urlopen(&quot;http:&#x2F;&#x2F;www.ba"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-a@main/img/137f30002b2fd221da0e9.jpg"><meta property="article:published_time" content="2020-03-24T08:40:49.000Z"><meta property="article:modified_time" content="2020-12-24T08:11:22.473Z"><meta property="article:author" content="HALO"><meta property="article:tag" content="Python"><meta property="article:tag" content="爬虫"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-a@main/img/137f30002b2fd221da0e9.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://halo123.top/2020/03/24/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-resources@latest/css/butterflyindex.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?874122390435717e6f6a55f14b9d7271";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-8ZMD16RCP5"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-8ZMD16RCP5")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:400},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,source:{jQuery:"https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js",justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js",css:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css"},fancybox:{js:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js",css:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isanchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2020-12-24 16:11:22"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,o){if(0===o)return;const n=864e5*o,a={value:t,expiry:(new Date).getTime()+n};localStorage.setItem(e,JSON.stringify(a))},get:function(e){const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!((new Date).getTime()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=e=>new Promise((t,o)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=o,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,t())},document.head.appendChild(n)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));const n=saveToLocal.get("global-font-size");void 0!==n&&document.documentElement.style.setProperty("--global-font-size",n+"px")})(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-resources@latest/css/bilibili-banner.min.css" media="defer" onload='this.media="screen"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-resources@latest/css/butterflymin.css" media="defer" onload='this.media="screen"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css" media="defer" onload='this.media="all"'><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="HALO" type="application/atom+xml"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://img.imgdb.cn/item/608289f3d1a9ae528feb09a8.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">73</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">50</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">31</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>Categories</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw fas fa-envelope"></i> <span>Message</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-a@main/img/137f30002b2fd221da0e9.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">HALO</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>Categories</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw fas fa-envelope"></i> <span>Message</span></a></div></div><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="winterBanner"><div class="view"><img class="morning" src="https://halo-blog-img.oss-cn-hangzhou.aliyuncs.com/BiliBiliBanner/winter/bilibili-winter-view-1.png" alt=""><img class="afternoon" src="https://halo-blog-img.oss-cn-hangzhou.aliyuncs.com/BiliBiliBanner/winter/bilibili-winter-view-2.png" alt=""><video class="evening" autoplay loop muted><source src="https://halo-blog-img.oss-cn-hangzhou.aliyuncs.com/BiliBiliBanner/winter/bilibili-winter-view-3.webm" type="video/webm"></video><img class="window-cover" src="https://halo-blog-img.oss-cn-hangzhou.aliyuncs.com/BiliBiliBanner/winter/bilibili-winter-view-3-snow.png" alt=""></div><div class="tree"><img class="morning" src="https://halo-blog-img.oss-cn-hangzhou.aliyuncs.com/BiliBiliBanner/winter/bilibili-winter-tree-1.png" alt=""><img class="afternoon" src="https://halo-blog-img.oss-cn-hangzhou.aliyuncs.com/BiliBiliBanner/winter/bilibili-winter-tree-2.png" alt=""><img class="evening" src="https://halo-blog-img.oss-cn-hangzhou.aliyuncs.com/BiliBiliBanner/winter/bilibili-winter-tree-3.png" alt=""></div></div><script async data-pjax src="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-resources@latest/js/bilibiliBanner.min.js"></script><div id="post-info"><h1 class="post-title">Python网络数据采集</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-03-24T08:40:49.000Z" title="发表于 2020-03-24 16:40:49">2020-03-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-12-24T08:11:22.473Z" title="更新于 2020-12-24 16:11:22">2020-12-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/">Python</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Python网络数据采集"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>Python网络数据采集笔记</p><hr><h2 id="网络数据采集的基本原理"><a class="header-anchor" href="#网络数据采集的基本原理"></a>网络数据采集的基本原理</h2><p>对网络爬虫通常的想法：</p><ul><li>通过网站域名获取 HTML 数据</li><li>根据目标信息解析数据</li><li>存储目标信息</li><li>如果有必要，移动到另一个网页重复这个过程</li></ul><h2 id="Python实现网络连接"><a class="header-anchor" href="#Python实现网络连接"></a>Python实现网络连接</h2><p>使用python获取网页，代码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(html.read())</span><br></pre></td></tr></table></figure><h3 id="urllib"><a class="header-anchor" href="#urllib"></a>urllib</h3><p>urllib 是 Python 的标准库，包含了从网络请求数据，处理cookie，甚至改变像请求头和用户代理这些元数据的函数。</p><p>urlopen 用来打开并读取一个从网络获取的远程对象。</p><blockquote><p>Python 2.x 里的的是 urllib2 库，在 Python 3.x 里，urllib2 改名为 urllib</p></blockquote><h3 id="BeautifulSoup"><a class="header-anchor" href="#BeautifulSoup"></a>BeautifulSoup</h3><p>BeautifulSoup通过定位 HTML 标签来 格式化和组织复杂的网络信息，用简单易用的 Python 对象为我们展现 XML 结构信息。</p><p>Pycharm可以自动导入其他安装可参考该<a target="_blank" rel="noopener" href="https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/#id8">文档</a>，有关Python虚拟环境可参考该<a target="_blank" rel="noopener" href="https://lanqilu.github.io/2019/10/12/Python/%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83venv/">文章</a></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure><p>使用BeautifulSoup</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">html = urlopen(<span class="string">&quot;https://lanqilu.github.io/&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html.read())</span><br><span class="line"><span class="built_in">print</span>(bsObj.h1)</span><br></pre></td></tr></table></figure><h3 id="网络连接异常"><a class="header-anchor" href="#网络连接异常"></a>网络连接异常</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html = urlopen(<span class="string">&quot;https://lanqilu.github.io/&quot;</span>)</span><br></pre></td></tr></table></figure><p>可能发生的异常有两种</p><ul><li>网页在服务器上不存在（或者获取页面的时候出现错误）</li><li>服务器不存在</li></ul><p>第一种异常发生时，程序会返回 HTTP 错误。可以查看<a target="_blank" rel="noopener" href="https://lanqilu.github.io/2020/03/21/Web/HTTP%E7%8A%B6%E6%80%81%E7%A0%81/">HTTP状态码</a>。所有类似情形，urlopen 函数都会抛出“HTTPError”异常</p><p>处理方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> HTTPError</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    html = urlopen(<span class="string">&quot;https://lanqilu.github.io/2018&quot;</span>) <span class="comment"># 异常网站 </span></span><br><span class="line"><span class="keyword">except</span> HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line">    <span class="comment"># 返回空值，中断程序，或者执行另一个方案</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;程序继续&quot;</span>)</span><br><span class="line"><span class="comment"># 注意：如果你已经在上面异常捕捉那一段代码里返回或中断（break）</span></span><br><span class="line"><span class="comment"># 那么就不需要使用else语句了，这段代码也不会执行</span></span><br></pre></td></tr></table></figure><p>如果服务器不存在（URL链接打不开），urlopen 会返回一个 None 对象。</p><p>要调用的标签不存在，BeautifulSoup 就会返回 None 对象</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> HTTPError</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTitle</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = urlopen(url)</span><br><span class="line">    <span class="keyword">except</span> HTTPError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        bsObj = BeautifulSoup(html.read(), <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">        title = bsObj.body.h1</span><br><span class="line">    <span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> title</span><br><span class="line"></span><br><span class="line">title = getTitle(<span class="string">&quot;https://www.runoob.com/&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> title <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Title could not be found&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(title)</span><br></pre></td></tr></table></figure><h2 id="HTML解析"><a class="header-anchor" href="#HTML解析"></a>HTML解析</h2><p>属性查找标签的方法，标签组的使用，以及标签解析树的导航过程</p><p>网络爬虫可以通过 class 属性的值，轻松地区分出两种不同的标签。</p><p>例如：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;red&quot;</span>&gt;</span>Heavens! what a virulent attack!<span class="tag">&lt;/<span class="name">span</span>&gt;</span>&quot; replied <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=</span></span><br><span class="line"><span class="tag">&quot;<span class="attr">green</span>&quot;&gt;</span>the prince<span class="tag">&lt;/<span class="name">span</span>&gt;</span>, not in the least disconcerted by this reception.</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line"><span class="comment"># 爬取页面</span></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/warandpeace.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html, features=<span class="string">&quot;lxml&quot;</span>) <span class="comment"># features 选择解析器</span></span><br><span class="line"><span class="comment"># 以用 findAll 函数抽取只包含在 &lt;span class=&quot;green&quot;&gt;&lt;/span&gt; 标签里的文字</span></span><br><span class="line">nameList = bsObj.findAll(<span class="string">&quot;span&quot;</span>, &#123;<span class="string">&quot;class&quot;</span>: <span class="string">&quot;green&quot;</span>&#125;)</span><br><span class="line"><span class="comment"># 打印输出</span></span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> nameList:</span><br><span class="line">    <span class="built_in">print</span>(name.get_text())</span><br></pre></td></tr></table></figure><blockquote><p><code>get_text()</code></p><p><code>.get_text()</code> 会把正在处理的 HTML 文档中所有的标签都清除，然后返回 一个只包含文字的字符串。假如你正在处理一个包含许多超链接、段落和标签的大段源代码，那么 <code>.get_text()</code> 会把这些超链接、段落和标签都清除掉， 只剩下一串不带标签的文字。</p></blockquote><h3 id="BeautifulSoup的find-和findAll"><a class="header-anchor" href="#BeautifulSoup的find-和findAll"></a>BeautifulSoup的<code>find()</code>和<code>findAll()</code></h3><p><code>findAll</code>函数通过标签的名称和属性来查找标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">findAll(tag, attributes, recursive, text, limit, keywords)</span><br><span class="line">find(tag, attributes, recursive, text, keywords)</span><br></pre></td></tr></table></figure><p><code>tag</code>标签参数，可以传一个标签的名称或多个标签名称组成的 Python 列表做标签参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.findAll(&#123;<span class="string">&quot;h1&quot;</span>,<span class="string">&quot;h2&quot;</span>,<span class="string">&quot;h3&quot;</span>,<span class="string">&quot;h4&quot;</span>,<span class="string">&quot;h5&quot;</span>,<span class="string">&quot;h6&quot;</span>&#125;)</span><br></pre></td></tr></table></figure><p><code>attributes</code>属性参数，是用一个 Python 字典封装一个标签的若干属性和对应的属性值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.findAll(<span class="string">&quot;span&quot;</span>, &#123;<span class="string">&quot;class&quot;</span>:&#123;<span class="string">&quot;green&quot;</span>, <span class="string">&quot;red&quot;</span>&#125;&#125;)</span><br></pre></td></tr></table></figure><p><code>recursive</code>递归参数，是一个布尔变量，设置为True，查找标签参数的所有子标签，以及子标签的子标签；设置为 False，就只查找文档的一级标签。（默认值是 True）</p><p><code>text</code>文本参数，是用标签的文本内容去匹配，而不是用标签的属性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#%%</span></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/warandpeace.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html, features=<span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">nameList = bsObj.findAll(text=<span class="string">&quot;the prince&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(nameList))  <span class="comment"># 7</span></span><br></pre></td></tr></table></figure><p><code>limit</code>范围限制参数，只用于<code>findAll</code>方法，获得的前几项结果是按照网页上的顺序排序</p><blockquote><p><code>find</code>等价于<code>findAll</code>的<code>limit</code>等于1时的情形</p></blockquote><p><code>keyword</code>关键词参数，用于选择具有指定属性的标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#%%</span></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/warandpeace.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html, features=<span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">allText = bsObj.findAll(<span class="built_in">id</span>=<span class="string">&quot;text&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(allText[<span class="number">0</span>].get_text())</span><br></pre></td></tr></table></figure><blockquote><p><code>class</code>保留词问题</p><p><code>bsObj.findAll(class=&quot;green&quot;)</code>语法错误，解决方案<code>bsObj.findAll(class_=&quot;green&quot;)</code>或<code>bsObj.findAll(&quot;&quot;, &#123;&quot;class&quot;:&quot;green&quot;&#125;)</code></p></blockquote><h3 id="其他BeautifulSoup对象"><a class="header-anchor" href="#其他BeautifulSoup对象"></a>其他BeautifulSoup对象</h3><ul><li><code>NavigableString</code>对象：用来表示标签里的文字，不是标签</li><li><code>Comment</code>对象：用来查找 HTML 文档的注释标签</li></ul></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><div class="post_share"></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i> <span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/04/06/Django/" title="Django"><img class="cover" src="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-a@main/img/137f30002b2fd221da0e9.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-06</div><div class="title">Django</div></div></a></div><div><a href="/2020/03/23/Java书单/" title="计算机书单"><img class="cover" src="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-a@main/img/2020-09-10-19-33-02-720.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-03-23</div><div class="title">计算机书单</div></div></a></div><div><a href="/2019/10/01/函数式编程/" title="函数式编程"><img class="cover" src="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-a@main/img/2020-09-10-19-33-02-720.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-10-01</div><div class="title">函数式编程</div></div></a></div><div><a href="/2020/03/27/正则表达式/" title="正则表达式"><img class="cover" src="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-a@main/img/137f30002b2fd221da0e9.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-03-27</div><div class="title">正则表达式</div></div></a></div><div><a href="/2019/07/22/科学计算之NumPy/" title="科学计算之NumPy"><img class="cover" src="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-a@main/img/2020-09-10-19-33-02-720.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-07-22</div><div class="title">科学计算之NumPy</div></div></a></div><div><a href="/2019/10/18/面向对象/" title="面向对象"><img class="cover" src="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-a@main/img/137f30002b2fd221da0e9.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-10-18</div><div class="title">面向对象</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">网络数据采集的基本原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Python%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5"><span class="toc-number">2.</span> <span class="toc-text">Python实现网络连接</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#urllib"><span class="toc-number">2.1.</span> <span class="toc-text">urllib</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BeautifulSoup"><span class="toc-number">2.2.</span> <span class="toc-text">BeautifulSoup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E5%BC%82%E5%B8%B8"><span class="toc-number">2.3.</span> <span class="toc-text">网络连接异常</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HTML%E8%A7%A3%E6%9E%90"><span class="toc-number">3.</span> <span class="toc-text">HTML解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BeautifulSoup%E7%9A%84find-%E5%92%8CfindAll"><span class="toc-number">3.1.</span> <span class="toc-text">BeautifulSoup的find()和findAll()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96BeautifulSoup%E5%AF%B9%E8%B1%A1"><span class="toc-number">3.2.</span> <span class="toc-text">其他BeautifulSoup对象</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By HALO</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div></div><hr><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-resources@latest/js/butterflyutils.js"></script><script src="https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-resources@latest/js/butterflymain.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function addGitalkSource(){const e=document.createElement("link");e.rel="stylesheet",e.href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css",document.getElementsByTagName("head")[0].appendChild(e)}function loadGitalk(){function e(){new Gitalk(Object.assign({clientID:"e5a3e7481d96cd2d0a56",clientSecret:"ae9c98707484f2afb1db73120ce2f3347afb32eb",repo:"BlogResources",owner:"lanqilu",admin:["lanqilu"],id:"74890a27a5e7f9ce256d68c3beb64872",language:"zh-CN",perPage:10,distractionFreeMode:!1,pagerDirection:"last",createIssueManually:!0,updateCountCallback:commentCount},null)).render("gitalk-container")}"function"==typeof Gitalk?e():(addGitalkSource(),getScript("https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js").then(e))}function commentCount(e){let t=document.querySelector("#post-meta .gitalk-comment-count");t&&(t.innerHTML=e)}{function loadOtherComment(){loadGitalk()}loadGitalk()}</script></div><script defer src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/hexo-theme-volantis@latest/source/js/issues.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>